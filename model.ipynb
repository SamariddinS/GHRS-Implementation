{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "dataPath = 'data/x_train_alpha/'\n",
    "X_train = pd.read_pickle(dataPath +\n",
    "                         'x_train_alpha(0.02).pkl').values.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize data\n",
    "scaler = StandardScaler() \n",
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define autoencoder\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, encoded_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(nn.Linear(input_dim, 128), nn.ReLU(),\n",
    "                                     nn.Linear(128, 64), nn.ReLU(),\n",
    "                                     nn.Linear(64, encoded_dim))\n",
    "        self.decoder = nn.Sequential(nn.Linear(encoded_dim, 64), nn.ReLU(),\n",
    "                                     nn.Linear(64, 128), nn.ReLU(),\n",
    "                                     nn.Linear(128, input_dim), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 1.2203\n",
      "Epoch [20/100], Loss: 1.1205\n",
      "Epoch [30/100], Loss: 1.0045\n",
      "Epoch [40/100], Loss: 0.9986\n",
      "Epoch [50/100], Loss: 0.9890\n",
      "Epoch [60/100], Loss: 0.9620\n",
      "Epoch [70/100], Loss: 0.9386\n",
      "Epoch [80/100], Loss: 0.9300\n",
      "Epoch [90/100], Loss: 0.9272\n",
      "Epoch [100/100], Loss: 0.9259\n"
     ]
    }
   ],
   "source": [
    "# Train autoencoder\n",
    "input_dim = X_train.shape[1]\n",
    "encoded_dim = 10\n",
    "autoencoder = Autoencoder(input_dim, encoded_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    inputs = torch.from_numpy(X_train).float()\n",
    "    encoded, decoded = autoencoder(inputs)\n",
    "    loss = criterion(decoded, inputs)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs,\n",
    "                                                   loss.item()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(autoencoder.encoder, 'models/autoencoder.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved encoder model\n",
    "# encoder = torch.load('models/autoencoder.pt')\n",
    "# with torch.no_grad():\n",
    "#     encoded_X_train = encoder(torch.from_numpy(X_train)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract encoded features\n",
    "encoded_features, _ = autoencoder(torch.from_numpy(X_train).float())\n",
    "encoded_features = encoded_features.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save encoded features to file\n",
    "encoded_features_df = pd.DataFrame(encoded_features)\n",
    "encoded_features_df.to_pickle('data/encoded_features/encoded_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster users using encoded features\n",
    "kmeans = KMeans(n_clusters=5, random_state=0, n_init=10).fit(encoded_features)\n",
    "cluster_labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: 292 users\n",
      "Cluster 1: 187 users\n",
      "Cluster 2: 13 users\n",
      "Cluster 3: 351 users\n",
      "Cluster 4: 100 users\n"
     ]
    }
   ],
   "source": [
    "# Print cluster sizes\n",
    "for i in range(5):\n",
    "    print(f\"Cluster {i}: {np.sum(cluster_labels == i)} users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.42\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the clustering performance using a clustering metric\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "silhouette = silhouette_score(encoded_features, cluster_labels)\n",
    "print(\"Silhouette Score: {:.2f}\".format(silhouette))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the encoded features\n",
    "X_encoded = pd.read_pickle(\"data/encoded_features/encoded_features.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform clustering using KMeans\n",
    "n_clusters = 5\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init=10).fit(X_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume we want to get top-10 recommendations for user with UID 123\n",
    "user_id = 1\n",
    "recommendation_count = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the cluster assignment for the user\n",
    "user_index = X_encoded.index.get_loc(user_id)\n",
    "user_cluster = kmeans.labels_[user_index]\n",
    "\n",
    "# get the indices of all users in the same cluster\n",
    "cluster_indices = np.where(kmeans.labels_ == user_cluster)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the ratings data\n",
    "cluster_ratings = pd.read_csv(\"datasets/ml-100k/ua.base\", delimiter='\\t', names=['UID', 'MID', 'rate', 'timestamp'], usecols=[0, 1, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ratings of all movies by users in the same cluster\n",
    "cluster_ratings = cluster_ratings.loc[cluster_ratings['UID'].isin(X_encoded.iloc[cluster_indices].index)][['MID', 'rate']]\n",
    "\n",
    "# compute the average rating for each movie\n",
    "avg_ratings = cluster_ratings.groupby(['MID']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the movies by their average rating and get the top-10 recommendations\n",
    "top_n_recommendations = avg_ratings.sort_values(by='rate', ascending=False).head(recommendation_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rate\n",
       "MID       \n",
       "851    5.0\n",
       "1656   5.0\n",
       "1293   5.0\n",
       "1295   5.0\n",
       "1612   5.0\n",
       "626    5.0\n",
       "1599   5.0\n",
       "1592   5.0\n",
       "814    5.0\n",
       "1275   5.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the u.item file\n",
    "item_df = pd.read_csv('datasets/ml-100k/u.item', sep='|', encoding='latin-1', header=None, usecols=[0,1], names=['MID', 'name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two or Three Things I Know About Her (1966)\n",
      "Little City (1998)\n",
      "Star Kid (1997)\n",
      "Kicked in the Head (1997)\n",
      "Leading Man, The (1996)\n",
      "So Dear to My Heart (1949)\n",
      "Someone Else's America (1995)\n",
      "Magic Hour, The (1998)\n",
      "Great Day in Harlem, A (1994)\n",
      "Killer (Bulletproof Heart) (1994)\n"
     ]
    }
   ],
   "source": [
    "# Recommendations top-n\n",
    "for mid in top_n_recommendations.index.values:\n",
    "    movie_name = item_df.loc[item_df['MID'] == mid]['name'].values[0]\n",
    "    print(movie_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toy Story (1995)\n",
      "Aliens (1986)\n",
      "Raiders of the Lost Ark (1981)\n",
      "Princess Bride, The (1987)\n",
      "Empire Strikes Back, The (1980)\n",
      "Cinema Paradiso (1988)\n",
      "Wrong Trousers, The (1993)\n",
      "Monty Python and the Holy Grail (1974)\n",
      "Manon of the Spring (Manon des sources) (1986)\n",
      "Jean de Florette (1986)\n",
      "Monty Python's Life of Brian (1979)\n",
      "Sleeper (1973)\n",
      "Swingers (1996)\n",
      "Big Night (1996)\n",
      "Bound (1996)\n",
      "Godfather, The (1972)\n",
      "Lone Star (1996)\n",
      "Maya Lin: A Strong Clear Vision (1994)\n",
      "Haunted World of Edward D. Wood Jr., The (1995)\n",
      "Wallace & Gromit: The Best of Aardman Animation (1996)\n",
      "Horseman on the Roof, The (Hussard sur le toit, Le) (1995)\n",
      "Truth About Cats & Dogs, The (1996)\n",
      "Mystery Science Theater 3000: The Movie (1996)\n",
      "Kids in the Hall: Brain Candy (1996)\n",
      "Fargo (1996)\n",
      "Brazil (1985)\n",
      "Good, The Bad and The Ugly, The (1966)\n",
      "Welcome to the Dollhouse (1995)\n",
      "12 Angry Men (1957)\n",
      "Full Monty, The (1997)\n",
      "Chasing Amy (1997)\n",
      "Contact (1997)\n",
      "Pillow Book, The (1995)\n",
      "Chasing Amy (1997)\n",
      "Kolya (1996)\n",
      "Mars Attacks! (1996)\n",
      "Star Trek: The Wrath of Khan (1982)\n",
      "Ridicule (1996)\n",
      "Sling Blade (1996)\n",
      "Breaking the Waves (1996)\n",
      "When Harry Met Sally... (1989)\n",
      "Young Frankenstein (1974)\n",
      "Cyrano de Bergerac (1990)\n",
      "Back to the Future (1985)\n",
      "Nikita (La Femme Nikita) (1990)\n",
      "Graduate, The (1967)\n",
      "Dead Poets Society (1989)\n",
      "Terminator, The (1984)\n",
      "Amadeus (1984)\n",
      "Henry V (1989)\n",
      "Alien (1979)\n",
      "Return of the Jedi (1983)\n",
      "Terminator 2: Judgment Day (1991)\n",
      "Gattaca (1997)\n",
      "Dolores Claiborne (1994)\n",
      "Nightmare Before Christmas, The (1993)\n",
      "Three Colors: Blue (1993)\n",
      "Three Colors: Red (1994)\n",
      "Antonia's Line (1995)\n",
      "Priest (1994)\n",
      "French Twist (Gazon maudit) (1995)\n",
      "Professional, The (1994)\n",
      "Mr. Holland's Opus (1995)\n",
      "Star Wars (1977)\n",
      "Hoop Dreams (1994)\n",
      "Postino, Il (1994)\n",
      "Mighty Aphrodite (1995)\n",
      "Crumb (1994)\n",
      "Searching for Bobby Fischer (1993)\n",
      "Remains of the Day, The (1993)\n",
      "Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)\n",
      "Eat Drink Man Woman (1994)\n",
      "Dead Man Walking (1995)\n",
      "Blade Runner (1982)\n",
      "Clerks (1994)\n",
      "Usual Suspects, The (1995)\n",
      "Shawshank Redemption, The (1994)\n",
      "Jurassic Park (1993)\n",
      "Hudsucker Proxy, The (1994)\n",
      "Apollo 13 (1995)\n",
      "Strange Days (1995)\n",
      "Birdcage, The (1996)\n",
      "Akira (1988)\n",
      "This Is Spinal Tap (1984)\n",
      "Indiana Jones and the Last Crusade (1989)\n",
      "Unbearable Lightness of Being, The (1988)\n",
      "Disclosure (1994)\n",
      "Unforgiven (1992)\n",
      "Bridge on the River Kwai, The (1957)\n",
      "Aladdin (1992)\n",
      "Pink Floyd - The Wall (1982)\n",
      "Taxi Driver (1976)\n",
      "Twelve Monkeys (1995)\n",
      "unknown\n",
      "Men in Black (1997)\n",
      "When the Cats Away (Chacun cherche son chat) (1996)\n",
      "Shall We Dance? (1996)\n",
      "Fifth Element, The (1997)\n",
      "Austin Powers: International Man of Mystery (1997)\n",
      "Grosse Pointe Blank (1997)\n",
      "Last of the Mohicans, The (1992)\n",
      "Sneakers (1992)\n",
      "Raising Arizona (1987)\n",
      "Citizen Ruth (1996)\n",
      "Jaws (1975)\n",
      "Star Trek IV: The Voyage Home (1986)\n",
      "Star Trek III: The Search for Spock (1984)\n",
      "Sting, The (1973)\n",
      "White Balloon, The (1995)\n",
      "Star Trek: First Contact (1996)\n",
      "Braveheart (1995)\n",
      "Star Trek VI: The Undiscovered Country (1991)\n",
      "Psycho (1960)\n",
      "Right Stuff, The (1983)\n",
      "Fugitive, The (1993)\n",
      "Four Rooms (1995)\n",
      "Carlito's Way (1993)\n",
      "2001: A Space Odyssey (1968)\n",
      "Citizen Kane (1941)\n",
      "Gone with the Wind (1939)\n",
      "Wizard of Oz, The (1939)\n",
      "Firm, The (1993)\n",
      "Supercop (1992)\n",
      "Hot Shots! Part Deux (1993)\n",
      "Brother Minister: The Assassination of Malcolm X (1994)\n",
      "Frighteners, The (1996)\n",
      "Independence Day (ID4) (1996)\n",
      "Robert A. Heinlein's The Puppet Masters (1994)\n",
      "Sleepless in Seattle (1993)\n",
      "Moll Flanders (1996)\n",
      "Diabolique (1996)\n",
      "So I Married an Axe Murderer (1993)\n",
      "Silence of the Lambs, The (1991)\n",
      "Unhook the Stars (1996)\n",
      "Willy Wonka and the Chocolate Factory (1971)\n",
      "Raging Bull (1980)\n",
      "Pulp Fiction (1994)\n",
      "Exotica (1994)\n",
      "Godfather: Part II, The (1974)\n",
      "Blues Brothers, The (1980)\n",
      "Army of Darkness (1993)\n",
      "Ed Wood (1994)\n",
      "GoodFellas (1990)\n",
      "Legends of the Fall (1994)\n",
      "Madness of King George, The (1994)\n",
      "Quiz Show (1994)\n",
      "Mask, The (1994)\n",
      "What's Eating Gilbert Grape (1993)\n",
      "While You Were Sleeping (1995)\n",
      "Return of the Pink Panther, The (1974)\n",
      "On Golden Pond (1981)\n",
      "Top Gun (1986)\n",
      "Platoon (1986)\n",
      "Reservoir Dogs (1992)\n",
      "Crow, The (1994)\n",
      "Die Hard (1988)\n"
     ]
    }
   ],
   "source": [
    "# Movies user rated about 4-5\n",
    "data = pd.read_csv(\n",
    "    \"datasets/ml-100k/ua.base\",\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"UID\", \"MID\", \"rate\", \"timestamp\"],\n",
    ")\n",
    "data[\"UID\"] = data[\"UID\"].astype(int)\n",
    "data[\"rate\"] = data[\"rate\"].astype(int)\n",
    "data = data[data[\"rate\"] > 3]\n",
    "data = data[data[\"UID\"] == user_id]\n",
    "data = data.sort_values(by=\"rate\", ascending=False)\n",
    "data = data.drop_duplicates(subset=[\"MID\"], keep=\"first\")\n",
    "data = data.drop([\"UID\", \"rate\", \"timestamp\"], axis=1)\n",
    "\n",
    "for mid in data[\"MID\"]:\n",
    "    movie_name = item_df.loc[item_df[\"MID\"] == mid][\"name\"].values[0]\n",
    "    print(movie_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
